{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Weekly Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We need to load in these libraries into our notebook in order to query, load, manipulate and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from cloud_sql_connector import DBConfig, getconn\n",
    "import sqlalchemy\n",
    "\n",
    "%load_ext sql\n",
    "%config SqlMagic.displaylimit = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This will create the connection to the database and prep the jupyter magic for SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Database connection setup\n",
    "config = DBConfig(\n",
    "    instance_name=os.getenv('DATABASE_INSTANCE_CONNECTION_NAME'),\n",
    "    database=os.getenv('DATABASE_NAME'),\n",
    "    user=os.getenv('DATABASE_USERNAME'),\n",
    "    ip_type=\"public\",\n",
    "    schema=os.getenv('DATABASE_SCHEMA')\n",
    ")\n",
    "\n",
    "def get_conn():\n",
    "    return getconn(config)\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql+pg8000://\",\n",
    "    creator=get_conn\n",
    ")\n",
    "\n",
    "print(\"Cloud SQL engine created:\", engine)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(sqlalchemy.text(\"SELECT 1 AS test\"))\n",
    "        print(\"✅ Connection test:\", result.fetchone())\n",
    "except Exception as e:\n",
    "    print(\"❌ Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Weekly running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Always use notebook folder as base\n",
    "notebook_dir = Path(\".\")  # papermill cwd will set this\n",
    "\n",
    "# Output directory (same as notebook folder, no extra 'daily')\n",
    "output_dir = notebook_dir\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "datestr = (datetime.now() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "filename = output_dir / f\"weekly_totals_till_{datestr}.csv\"\n",
    "print(\"CSV will be saved to:\", filename)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Weekly submitted query\n",
    "weekly_submitted_query = \"\"\"\n",
    "SELECT count(r.*) AS number_of_names_submitted\n",
    "FROM requests r\n",
    "WHERE date(r.submitted_date at time zone 'utc' at time zone 'pst')  \n",
    "      > date(current_date - 1 - interval '1 weeks')\n",
    "  AND date(r.submitted_date at time zone 'utc' at time zone 'pst')  \n",
    "      <= date(current_date - 1)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stat_weekly_submitted_df = pd.read_sql(weekly_submitted_query, engine)\n",
    "    display(stat_weekly_submitted_df.head())\n",
    "except Exception as e:\n",
    "    print(\"Error running weekly submitted query:\", e)\n",
    "    stat_weekly_submitted_df = pd.DataFrame()\n",
    "\n",
    "# Save submitted section to CSV\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "    if stat_weekly_submitted_df.empty:\n",
    "        f.write('No Data Retrieved for Weekly Submitted\\n')\n",
    "    else:\n",
    "        stat_weekly_submitted_df.to_csv(f, sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_completed_query = \"\"\"\n",
    "WITH Detail AS \n",
    "(\n",
    "    SELECT e.user_id,\n",
    "           (SELECT username FROM users u WHERE u.id=e.user_id) AS examiner,\n",
    "           count(e.*) FILTER (WHERE e.state_cd = 'APPROVED')  AS approved,\n",
    "           count(e.*) FILTER (WHERE e.state_cd = 'REJECTED')  AS rejected,\n",
    "           count(e.*) FILTER (WHERE e.state_cd = 'CONDITIONAL')  AS conditional,\n",
    "           count(e.*) FILTER (WHERE e.state_cd = 'CANCELLED')  AS cancelled,\n",
    "           count(r.*) FILTER (WHERE r.priority_cd = 'Y') AS priorities,\n",
    "           count(e.*) + count(r.*) FILTER (WHERE r.priority_cd = 'Y') AS total\n",
    "    FROM events e,\n",
    "         requests r\n",
    "    WHERE e.user_id != 1\n",
    "      AND r.id = e.nr_id\n",
    "      AND date(e.event_dt at time zone 'utc' at time zone 'pst')  \n",
    "          > date(current_date - 1 - interval '1 weeks')\n",
    "      AND date(e.event_dt at time zone 'utc' at time zone 'pst')  \n",
    "          <= date(current_date - 1)\n",
    "      AND e.state_cd IN ('APPROVED','REJECTED','CONDITIONAL','CANCELLED')\n",
    "    GROUP BY e.user_id\n",
    ")\n",
    "SELECT * FROM Detail WHERE examiner LIKE '%idir%'\n",
    "UNION ALL\n",
    "SELECT null,\n",
    "       'SUM' AS examiner,\n",
    "       sum(approved) AS approved,\n",
    "       sum(rejected) AS rejected,\n",
    "       sum(conditional) AS conditional,\n",
    "       sum(cancelled) AS cancelled,\n",
    "       sum(priorities) AS priorities,\n",
    "       sum(total) AS total\n",
    "FROM Detail WHERE examiner LIKE '%idir%';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    stat_weekly_completed_df = pd.read_sql(weekly_completed_query, engine)\n",
    "except Exception as e:\n",
    "    print(\"Error running weekly completed query:\", e)\n",
    "    stat_weekly_completed_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not stat_weekly_completed_df.empty:\n",
    "    stat_weekly_completed_df['examiner'] = stat_weekly_completed_df['examiner'].astype(str).str.replace('idir/', '', regex=False)\n",
    "    stat_weekly_completed_df['approved+conditional_%'] = round(\n",
    "        ((stat_weekly_completed_df['approved'] + stat_weekly_completed_df['conditional']) / stat_weekly_completed_df['total']) * 100, 2\n",
    "    )\n",
    "    stat_weekly_completed_df['rejected_%'] = round(\n",
    "        (stat_weekly_completed_df['rejected'] / stat_weekly_completed_df['total']) * 100, 2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
    "    f.write('\\n\\nNumber of Names Processed:\\n')\n",
    "    if stat_weekly_completed_df.empty:\n",
    "        f.write('No Data Retrieved for Weekly Completed\\n')\n",
    "    else:\n",
    "        stat_weekly_completed_df.to_csv(f, sep=',', index=False)\n",
    "\n",
    "# %%\n",
    "# Verification\n",
    "print(\"CSV saved at:\", filename)\n",
    "print(\"Exists:\", os.path.exists(filename), \"Size (bytes):\", os.path.getsize(filename) if os.path.exists(filename) else \"N/A\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "3.8.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
